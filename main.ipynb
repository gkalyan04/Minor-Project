{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: praat-parselmouth in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.7.0 in c:\\users\\kalyan\\anaconda3\\envs\\project\\lib\\site-packages (from praat-parselmouth) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'quote' from 'urllib' (C:\\Users\\KALYAN\\anaconda3\\lib\\urllib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1b7844105b03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpraat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\parselmouth\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m ]\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParselmouth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParselmouthConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParselmouthException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\parselmouth\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Parselmouth Imports - Adapter Imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDFPInterface\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\parselmouth\\adapters\\dfp\\interface.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquote\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Parselmouth Imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'quote' from 'urllib' (C:\\Users\\KALYAN\\anaconda3\\lib\\urllib\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parselmouth\n",
    "from parselmouth.praat import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurePitch(voiceID, f0min, f0max, unit):\n",
    "    sound = parselmouth.Sound(voiceID) # read the sound\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)#create a praat pitch object\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    harmonicity05 = call(sound, \"To Harmonicity (cc)\", 0.01, 500, 0.1, 1.0)\n",
    "    hnr05 = call(harmonicity05, \"Get mean\", 0, 0)\n",
    "    harmonicity15 = call(sound, \"To Harmonicity (cc)\", 0.01, 1500, 0.1, 1.0)\n",
    "    hnr15 = call(harmonicity15, \"Get mean\", 0, 0)\n",
    "    harmonicity25 = call(sound, \"To Harmonicity (cc)\", 0.01, 2500, 0.1, 1.0)\n",
    "    hnr25 = call(harmonicity25, \"Get mean\", 0, 0)\n",
    "    harmonicity35 = call(sound, \"To Harmonicity (cc)\", 0.01, 3500, 0.1, 1.0)\n",
    "    hnr35 = call(harmonicity35, \"Get mean\", 0, 0)\n",
    "    harmonicity38 = call(sound, \"To Harmonicity (cc)\", 0.01, 3800, 0.1, 1.0)\n",
    "    hnr38 = call(harmonicity38, \"Get mean\", 0, 0)\n",
    "    return localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, hnr05, hnr15 ,hnr25 ,hnr35 ,hnr38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localJitter_list = [] \n",
    "localabsoluteJitter_list = [] \n",
    "rapJitter_list = [] \n",
    "ppq5Jitter_list = [] \n",
    "localShimmer_list =  [] \n",
    "localdbShimmer_list = [] \n",
    "apq3Shimmer_list = [] \n",
    "aqpq5Shimmer_list = [] \n",
    "apq11Shimmer_list =  [] \n",
    "hnr05_list = [] \n",
    "hnr15_list = [] \n",
    "hnr25_list = [] \n",
    "parkinson_list = [] \n",
    "file_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wave_file in glob.glob(\"audio/SpontaneousDialogue/PD/*.wav\"):\n",
    "    sound = parselmouth.Sound(wave_file)\n",
    "    (localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, hnr05, hnr15 ,hnr25 ,hnr35 ,hnr38) = measurePitch(sound, 75, 1000, \"Hertz\")\n",
    "    file_list.append(wave_file) \n",
    "    localJitter_list.append(localJitter) \n",
    "    localabsoluteJitter_list.append(localabsoluteJitter) \n",
    "    rapJitter_list.append(rapJitter)\n",
    "    ppq5Jitter_list.append(ppq5Jitter)\n",
    "    localShimmer_list.append(localShimmer)\n",
    "    localdbShimmer_list.append(localdbShimmer)\n",
    "    apq3Shimmer_list.append(apq3Shimmer)\n",
    "    aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "    apq11Shimmer_list.append(apq11Shimmer)\n",
    "    hnr05_list.append(hnr05)\n",
    "    hnr15_list.append(hnr15)\n",
    "    hnr25_list.append(hnr25)\n",
    "    parkinson_list.append(1) #1 parkinson file\n",
    "\n",
    "for wave_file in glob.glob(\"audio/ReadText/PD/*.wav\"):\n",
    "    sound = parselmouth.Sound(wave_file)\n",
    "    (localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, hnr05, hnr15 ,hnr25 ,hnr35 ,hnr38) = measurePitch(sound, 75, 1000, \"Hertz\")\n",
    "    file_list.append(wave_file) # make an ID list\n",
    "    localJitter_list.append(localJitter) # make a mean F0 list\n",
    "    localabsoluteJitter_list.append(localabsoluteJitter) # make a sd F0 list\n",
    "    rapJitter_list.append(rapJitter)\n",
    "    ppq5Jitter_list.append(ppq5Jitter)\n",
    "    localShimmer_list.append(localShimmer)\n",
    "    localdbShimmer_list.append(localdbShimmer)\n",
    "    apq3Shimmer_list.append(apq3Shimmer)\n",
    "    aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "    apq11Shimmer_list.append(apq11Shimmer)\n",
    "    hnr05_list.append(hnr05)\n",
    "    hnr15_list.append(hnr15)\n",
    "    hnr25_list.append(hnr25)\n",
    "    parkinson_list.append(1) #1 because parkinson file\n",
    "\n",
    "for wave_file in glob.glob(\"audio/SpontaneousDialogue/HC/*.wav\"):\n",
    "    sound = parselmouth.Sound(wave_file)\n",
    "    (localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, hnr05, hnr15 ,hnr25 ,hnr35 ,hnr38) = measurePitch(sound, 75, 1000, \"Hertz\")\n",
    "    file_list.append(wave_file) # make an ID list\n",
    "    localJitter_list.append(localJitter) # make a mean F0 list\n",
    "    localabsoluteJitter_list.append(localabsoluteJitter) # make a sd F0 list\n",
    "    rapJitter_list.append(rapJitter)\n",
    "    ppq5Jitter_list.append(ppq5Jitter)\n",
    "    localShimmer_list.append(localShimmer)\n",
    "    localdbShimmer_list.append(localdbShimmer)\n",
    "    apq3Shimmer_list.append(apq3Shimmer)\n",
    "    aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "    apq11Shimmer_list.append(apq11Shimmer)\n",
    "    hnr05_list.append(hnr05)\n",
    "    hnr15_list.append(hnr15)\n",
    "    hnr25_list.append(hnr25)\n",
    "    parkinson_list.append(0) #0 because healthy file\n",
    "\n",
    "for wave_file in glob.glob(\"audio/ReadText/HC/*.wav\"):\n",
    "    sound = parselmouth.Sound(wave_file)\n",
    "    (localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, hnr05, hnr15 ,hnr25 ,hnr35 ,hnr38) = measurePitch(sound, 75, 1000, \"Hertz\")\n",
    "    file_list.append(wave_file) # make an ID list\n",
    "    localJitter_list.append(localJitter) # make a mean F0 list\n",
    "    localabsoluteJitter_list.append(localabsoluteJitter) # make a sd F0 list\n",
    "    rapJitter_list.append(rapJitter)\n",
    "    ppq5Jitter_list.append(ppq5Jitter)\n",
    "    localShimmer_list.append(localShimmer)\n",
    "    localdbShimmer_list.append(localdbShimmer)\n",
    "    apq3Shimmer_list.append(apq3Shimmer)\n",
    "    aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "    apq11Shimmer_list.append(apq11Shimmer)\n",
    "    hnr05_list.append(hnr05)\n",
    "    hnr15_list.append(hnr15)\n",
    "    hnr25_list.append(hnr25)\n",
    "    parkinson_list.append(0) #0 because healthy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(np.column_stack([parkinson_list,localJitter_list, localabsoluteJitter_list, rapJitter_list, ppq5Jitter_list, localShimmer_list, localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, apq11Shimmer_list, hnr05_list, hnr15_list, hnr25_list]),\n",
    "                               columns=[\"Parkinson\",\"Jitter_rel\",\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\",\"Shim_loc\",\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\"Shi_APQ11\", \"hnr05\", \"hnr15\", \"hnr25\"])  #add these lists to pandas in the right order\n",
    "\n",
    "pred['hnr25'].fillna((pred['hnr25'].mean()), inplace=True) #Data cleaning because they may be NaN values\n",
    "pred['hnr15'].fillna((pred['hnr15'].mean()), inplace=True) #Data cleaning because they may be NaN values\n",
    "\n",
    "pred.to_csv(\"processed_results.csv\", index=False) # Write out the updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.6666666666666666\n",
      "test accuracy = 0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "parkinson = pd.read_csv(\"processed_results.csv\") #Loading CSV dataset\n",
    "\n",
    "predictors=[\"Jitter_rel\",\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\",\"Shim_loc\",\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\"Shi_APQ11\",\"hnr05\",\"hnr15\", \"hnr25\"] #Listing predictors\n",
    "\n",
    "for col in predictors: # Loop through all columns in predictors\n",
    "    if parkinson[col].dtype == 'object':  # check if column's type is object (text)\n",
    "        parkinson[col] = pd.Categorical(parkinson[col]).codes  # convert text to numerical\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(parkinson[predictors], parkinson['Parkinson'], test_size=0.25, random_state=1)        \n",
    "        \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_score = clf.score(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "\n",
    "print ('train accuracy =', train_score)\n",
    "print ('test accuracy =', test_score)\n",
    "\n",
    "# train accuracy = 0.6666666666666666\n",
    "# test accuracy = 0.631578947368421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainedModel.sav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf, \"trainedModel.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "def loadModel(PATH):\n",
    "    clf = joblib.load(PATH)\n",
    "    return clf\n",
    "\n",
    "def measurePitch(voiceID, f0min, f0max, unit):\n",
    "    sound = parselmouth.Sound(voiceID) # read the sound\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)#create a praat pitch object\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    harmonicity05 = call(sound, \"To Harmonicity (cc)\", 0.01, 500, 0.1, 1.0)\n",
    "    hnr05 = call(harmonicity05, \"Get mean\", 0, 0)\n",
    "    harmonicity15 = call(sound, \"To Harmonicity (cc)\", 0.01, 1500, 0.1, 1.0)\n",
    "    hnr15 = call(harmonicity15, \"Get mean\", 0, 0)\n",
    "    harmonicity25 = call(sound, \"To Harmonicity (cc)\", 0.01, 2500, 0.1, 1.0)\n",
    "    hnr25 = call(harmonicity25, \"Get mean\", 0, 0)\n",
    "    harmonicity35 = call(sound, \"To Harmonicity (cc)\", 0.01, 3500, 0.1, 1.0)\n",
    "    hnr35 = call(harmonicity35, \"Get mean\", 0, 0)\n",
    "    harmonicity38 = call(sound, \"To Harmonicity (cc)\", 0.01, 3800, 0.1, 1.0)\n",
    "    hnr38 = call(harmonicity38, \"Get mean\", 0, 0)\n",
    "    return localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, hnr05, hnr15 ,hnr25 ,hnr35 ,hnr38\n",
    "\n",
    "\n",
    "def predict(clf, wavPath):\n",
    "    file_list = []\n",
    "    localJitter_list = []\n",
    "    localabsoluteJitter_list = []\n",
    "    rapJitter_list = []\n",
    "    ppq5Jitter_list = []\n",
    "    localShimmer_list = []\n",
    "    localdbShimmer_list = []\n",
    "    apq3Shimmer_list = []\n",
    "    aqpq5Shimmer_list = []\n",
    "    apq11Shimmer_list = []\n",
    "    hnr05_list = []\n",
    "    hnr15_list = []\n",
    "    hnr25_list = []\n",
    "    hnr35_list = []\n",
    "    hnr38_list = []\n",
    "\n",
    "    sound = parselmouth.Sound(wavPath)\n",
    "    (localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer,\n",
    "     apq11Shimmer, hnr05, hnr15, hnr25, hnr35, hnr38) = measurePitch(sound, 75, 1000, \"Hertz\")\n",
    "    localJitter_list.append(localJitter)  # make a mean F0 list\n",
    "    localabsoluteJitter_list.append(localabsoluteJitter)  # make a sd F0 list\n",
    "    rapJitter_list.append(rapJitter)\n",
    "    ppq5Jitter_list.append(ppq5Jitter)\n",
    "    localShimmer_list.append(localShimmer)\n",
    "    localdbShimmer_list.append(localdbShimmer)\n",
    "    apq3Shimmer_list.append(apq3Shimmer)\n",
    "    aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "    apq11Shimmer_list.append(apq11Shimmer)\n",
    "    hnr05_list.append(hnr05)\n",
    "    hnr15_list.append(hnr15)\n",
    "    hnr25_list.append(hnr25)\n",
    "    hnr35_list.append(hnr35)\n",
    "    hnr38_list.append(hnr38)\n",
    "\n",
    "    toPred = pd.DataFrame(np.column_stack(\n",
    "        [localJitter_list, localabsoluteJitter_list, rapJitter_list, ppq5Jitter_list, localShimmer_list,\n",
    "         localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, apq11Shimmer_list, hnr05_list, hnr15_list,\n",
    "         hnr25_list]),\n",
    "                         columns=[\"Jitter_rel\", \"Jitter_abs\", \"Jitter_RAP\", \"Jitter_PPQ\", \"Shim_loc\", \"Shim_dB\",\n",
    "                                  \"Shim_APQ3\", \"Shim_APQ5\", \"Shi_APQ11\", \"hnr05\", \"hnr15\",\n",
    "                                  \"hnr25\"])  # add these lists to pandas in the right order\n",
    "\n",
    "    resp = clf.predict(toPred)\n",
    "    resp = str(resp)\n",
    "\n",
    "    if resp == \"[1.]\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# from RecognitionLib import *\n",
    "\n",
    "path = \"trainedModel.sav\" #Model path\n",
    "clf = loadModel(path) #Model loading\n",
    "\n",
    "print(predict(clf, \"kalyan_new.mpeg\"))#Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement RecognitionLib (from versions: none)\n",
      "ERROR: No matching distribution found for RecognitionLib\n"
     ]
    }
   ],
   "source": [
    "!pip install RecognitionLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinson = pd.read_csv(\"processed_results.csv\") #Loading CSV dataset\n",
    "\n",
    "predictors=[\"Jitter_rel\",\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\",\"Shim_loc\",\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\"Shi_APQ11\",\"hnr05\",\"hnr15\", \"hnr25\"] #Listing predictors\n",
    "\n",
    "# for col in predictors: # Loop through all columns in predictors\n",
    "#     if parkinson[col].dtype == 'object':  # check if column's type is object (text)\n",
    "#         parkinson[col] = pd.Categorical(parkinson[col]).codes  # convert text to numerical\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(parkinson[predictors], parkinson[['Parkinson']], test_size=0.05, random_state=1)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# y_train_flat = np.argmax(y_train, axis=1)\n",
    "# y_test_flat = np.argmax(y_test, axis=1)\n",
    "# y_train_flat = y_train_flat.astype(int)\n",
    "# y_test_flat = y_test_flat.astype(int)\n",
    "# input_shape = (X_train.shape[0], X_train.shape[1])\n",
    "# type(y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,X_train.shape[0], X_train.shape[1])\n",
    "X_test = X_test.values.reshape(-1,X_test.shape[0], X_test.shape[1])\n",
    "y_train = y_train.values.reshape(-1,y_train.shape[0], y_train.shape[1])\n",
    "y_test = y_test.values.reshape(-1,y_test.shape[0], y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,ProgbarLogger\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM RNN model ...\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 69, 128)           72192     \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 92,833\n",
      "Trainable params: 92,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build LSTM RNN model ...')\n",
    "import keras_metrics as km\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.20, return_sequences=True,input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "model.add(LSTM(units=32, dropout=0.05, recurrent_dropout=0.20, return_sequences=False))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc', km.binary_precision(), km.binary_recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started..... please wait.\n",
      "WARNING:tensorflow:From C:\\Users\\KALYAN\\anaconda3\\lib\\site-packages\\keras_metrics\\metrics.py:51: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`inputs` is now automatically inferred\n",
      "WARNING:tensorflow:From C:\\Users\\KALYAN\\anaconda3\\lib\\site-packages\\keras_metrics\\metrics.py:26: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.84014, saving model to .\\best_model_trained.hdf5\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00002: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00003: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00004: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00005: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00006: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00007: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00008: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00009: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00010: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00011: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00012: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00013: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00014: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00015: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00016: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00017: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00018: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00019: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00020: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00021: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00022: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00023: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00024: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00025: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00026: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00027: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00028: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00029: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00030: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00031: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00032: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00033: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00034: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00035: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00036: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00037: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00038: loss did not improve from 8.84014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00039: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00040: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00041: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00042: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00043: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00044: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00045: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00046: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00047: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00048: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00049: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00050: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00051: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00052: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00053: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00054: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00055: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00056: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00057: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00058: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00059: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00060: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00061: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00062: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00063: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00064: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00065: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00066: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00067: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00068: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00069: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00070: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00071: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00072: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00073: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00074: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00075: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00076: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00077: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00078: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00079: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00080: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00081: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00082: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00083: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00084: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00085: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00086: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00087: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00088: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00089: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00090: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00091: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00092: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00093: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00094: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00095: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00096: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00097: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00098: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00099: loss did not improve from 8.84014\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,precision,recall,lr\n",
      "\n",
      "Epoch 00100: loss did not improve from 8.84014\n",
      "training finised!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_EPOCHS=100\n",
    "MAX_BATCH=32\n",
    "best_model_file=\"./best_model_trained.hdf5\"\n",
    "\n",
    "callback=[ReduceLROnPlateau(patience=MAX_PATIENT, verbose=1),\n",
    "          ModelCheckpoint(filepath=best_model_file, monitor='loss', verbose=1, save_best_only=True)]\n",
    "\n",
    "print (\"training started..... please wait.\")\n",
    "# training\n",
    "history=model.fit(X_train, y_train, \n",
    "                  batch_size=MAX_BATCH, \n",
    "                  epochs=MAX_EPOCHS,\n",
    "                  verbose=0,\n",
    "                 callbacks=callback) \n",
    "\n",
    "print (\"training finised!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x00000183FFCCF828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "model train data score       :  42 %\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 69, 12) for input Tensor(\"lstm_29_input:0\", shape=(None, 69, 12), dtype=float32), but it was called on an input with incompatible shape (None, 4, 12).\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x00000183FFCCF828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "model test data score        :  50 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0) \n",
    "print (\"model train data score       : \",round(score[1]*100) , \"%\")\n",
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print (\"model test data score        : \",round(score[1]*100) , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
